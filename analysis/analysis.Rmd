---
title: "Data Analysis"
author: "Brendan Chapuis"
date: "4/10/2020"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries, include = FALSE}

library(lubridate)
library(randomForest)
library(tidymodels)
library(plotrix)
library(forcats)
library(gt)
library(broom)
library(rsample)
library(yardstick)
library(readr)
library(tidyverse)

```


```{r data, echo = FALSE}

dem_primary <- read_csv(
  "processed-data/dem_primary.csv",
  col_types = cols(
    state = col_character(),
    contest_date = col_date(format = ""),
    name = col_character(),
    date = col_date(format = ""),
    market_close = col_double(),
    poll_estimate = col_double(),
    poll_trend_adjusted = col_double(),
    date_dropped = col_date(format = "")
  )
)

final_results <- dem_primary %>% 
  filter(date == contest_date -1)
    
```


```{r analysis, echo = FALSE}

# Calculate prediction accuracy over time

thirty_day_primary <- dem_primary %>%
  filter(
    state %in% c(
      "California",
      "Georgia",
      "Iowa",
      "Kentucky",
      "Massachusetts",
      "Minnesota",
      "Montana",
      "New Hampshire",
      "New Jersey",
      "Nevada",
      "Oregon",
      "Rhode Island",
      "South Carolina",
      "Tennessee",
      "Texas",
      "Vermont",
      "Virginia",
      "West Virginia"
    ) &
      year == 2016 |
      state %in% c(
        "Wisconsin",
        "Washington",
        "North Carolina",
        "Mississippi",
        "Texas",
        "Virginia",
        "Utah",
        "Tennessee",
        "South Carolina",
        "Oklahoma",
        "Missouri",
        "Minnesota",
        "Michigan",
        "Maine",
        "Illinois",
        "Florida",
        "Colorado",
        "California",
        "Arizona",
        "Massachusetts",
        "Alabama",
        "Nevada",
        "New Hampshire",
        "Iowa"
      ) & year == 2020
  )

market_predictions <- function(days_before) {
  thirty_day_primary %>%
    filter(date == contest_date - days_before) %>%
    group_by(state, year) %>%
    arrange(desc(market_close)) %>%
    mutate(
      market_rank = 1:n(),
      market_winner = ifelse(market_rank == 1, 1, 0),
      market_correct = ifelse(market_winner == winner, 1, 0)
    ) %>%
    arrange(desc(poll_estimate)) %>%
    mutate(
      poll_rank = 1:n(),
      poll_winner = ifelse(poll_rank == 1, 1, 0),
      poll_correct = ifelse(poll_winner == winner, 1, 0)
    ) %>%
    ungroup() %>%
    filter(winner == 1, !is.na(market_close)) %>% 
    summarize(
      market_accuracy = round(sum(market_correct) / n() * 100, 2)
    ) %>% 
    pull(market_accuracy)
}

poll_predictions <- function(days_before) {
  thirty_day_primary %>%
    filter(date == contest_date - days_before) %>%
    group_by(state, year) %>%
    arrange(desc(poll_estimate)) %>%
    mutate(
      poll_rank = 1:n(),
      poll_winner = ifelse(poll_rank == 1, 1, 0),
      poll_correct = ifelse(poll_winner == winner, 1, 0)
    ) %>%
    ungroup() %>%
    filter(winner == 1, !is.na(poll_estimate)) %>% 
    summarize(
      poll_accuracy = round(sum(poll_correct) / n() * 100, 2)
    ) %>% 
    pull(poll_accuracy)
}

predictions_over_time <- tibble(days_before = c(1:30)) %>%
  mutate(
    market = map_dbl(days_before, market_predictions),
    poll = map_dbl(days_before, poll_predictions)
  )

# Table for accuracy over time

predictions_over_time %>%
  summarize(
    average_market_accuracy = paste(round(mean(market), 2), "%", sep = ""),
    average_poll_accuracy = paste(round(mean(poll), 2), "%", sep = "")
  ) %>%
  gt() %>%
  tab_header(title = "Average Accuracy of Predictions",
             subtitle = "For 50 Days Preceding Election") %>%
  cols_label(average_market_accuracy = "Average Market Accuracy",
             average_poll_accuracy = "Average Poll Accuracy")

# Plot for accuracy over time

predictions_over_time %>%
  pivot_longer(
    cols = c(market, poll),
    names_to = "prediction_type",
    values_to = "value"
  ) %>%
  ggplot(aes(x = days_before, y = value, color = prediction_type)) +
  geom_line() +
  theme_grey() +
  scale_x_reverse() +
  labs(
    title = "Changes in Prediction Accuracy Over Time",
    subtitle = "Calculated As Percent of Elections Correctly Predicted",
    x = "Days Before Election",
    y = "Accuracy of Predictions",
    color = "Prediction Type"
  ) +
  scale_color_discrete(labels = c("Prediction Market Price", "Polling Average")) +
  theme(legend.position = "bottom")

# Predictions - table

predictions <- final_results %>%
  group_by(state, year) %>% 
  arrange(desc(market_close)) %>% 
  mutate(market_rank = 1:n(),
         market_winner = ifelse(market_rank == 1, 1, 0),
         market_correct = ifelse(market_winner == winner, 1, 0),
         viable = ifelse(market_close > 0.01, 1, 0),
         viable_candidates = sum(viable)) %>%
  arrange(desc(poll_estimate)) %>% 
  mutate(poll_rank = 1:n(),
         poll_winner = ifelse(poll_rank == 1, 1, 0),
         poll_correct = ifelse(poll_winner == winner,1,0)) %>% 
  ungroup()

# Simple percent accuracy - table

predictions %>% 
  summarize(poll_accuracy = round(sum(poll_correct)/n() * 100, 2),
            market_accuracy = round(sum(market_correct)/n() * 100, 2)) %>% 
  gt() %>% 
  tab_header(title = "Percent Accuracy of Polls and Prediction Market",
             subtitle = "For Predicting Election Winner") %>% 
  cols_label(poll_accuracy = "Polling Average Accuracy",
             market_accuracy = "Market Price Accuracy")

# Percent error from prediction - table

final_results %>% 
  mutate(market_error = abs(market_close - vote_percent),
         poll_error = abs(poll_estimate - vote_percent)) %>%
  filter(!is.na(market_error) | !is.na(poll_error)) %>% 
  summarize(average_market_error = round(mean(market_error) * 100,2),
            average_poll_error = round(mean(poll_error)*100,2)) %>% 
  gt() %>% 
  tab_header(title = "Average Percent Error of Polls and Prediction Market",
             subtitle = "For Predicting Vote Percent") %>% 
  cols_label(average_market_error = "Market Average Error",
             average_poll_error = "Poll Average Error")


# Logistic model for predicting winner - table

logistic_mod <- logistic_reg() %>%
    set_engine("glm") %>%
    set_mode("classification")

logistic_mod %>%
  fit(factor(winner) ~ market_close + poll_estimate + viable_candidates, data = predictions) %>%
  predict(new_data = predictions) %>%
  bind_cols(predictions) %>%
  mutate(model_predicted = .pred_class) %>%
  mutate(model_correct = ifelse(model_predicted == winner, 1, 0)) %>%
  filter(winner == 1) %>%
  summarize(model_accuracy = sum(model_correct) / n()) %>%
  mutate(difference = round((model_accuracy - .8475) * 100, 2),
         model_accuracy = paste(round(model_accuracy * 100, 2), "%", sep = "")) %>%
  gt() %>%
  tab_header(title = "Accuracy of Logistic Model Predictions",
             subtitle = "Using Entire Original Data Set") %>%
  cols_label(model_accuracy = "Percent Accuracy of Model",
             difference = "Percentage Point Increase in Accuracy")


```