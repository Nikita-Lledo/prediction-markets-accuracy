---
title: "Data Analysis"
author: "Brendan Chapuis"
date: "4/10/2020"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries, include = FALSE}

library(lubridate)
library(randomForest)
library(tidymodels)
library(plotrix)
library(forcats)
library(gt)
library(broom)
library(rsample)
library(yardstick)
library(readr)
library(tidyverse)

```


```{r data, echo = FALSE}

dem_primary <- read_csv(
  "data/processed-data/dem_primary.csv",
  col_types = cols(
    state = col_character(),
    contest_date = col_date(format = ""),
    name = col_character(),
    date = col_date(format = ""),
    market_close = col_double(),
    poll_estimate = col_double(),
    poll_trend_adjusted = col_double(),
    date_dropped = col_date(format = "")
  )
)

final_results <- dem_primary %>% 
  filter(date == contest_date -1)
    
```


```{r analysis, echo = FALSE}



predictions <- final_results %>%
  group_by(state, year) %>% 
  arrange(desc(market_close)) %>% 
  mutate(market_rank = 1:n(),
         market_winner = ifelse(market_rank == 1, 1, 0),
         market_correct = ifelse(market_winner == winner, 1, 0)) %>%
  arrange(desc(poll_estimate)) %>% 
  mutate(poll_rank = 1:n(),
         poll_winner = ifelse(poll_rank == 1, 1, 0),
         poll_correct = ifelse(poll_winner == winner,1,0)) %>% 
  ungroup()

# Simple percent accuracy

predictions %>% 
  summarize(poll_accuracy = round(sum(poll_correct)/n() * 100, 2),
            market_accuracy = round(sum(market_correct)/n() * 100, 2)) %>% 
  gt() %>% 
  tab_header(title = "Percent Accuracy of Polls and Prediction Market",
             subtitle = "For Predicting Election Winner") %>% 
  cols_label(poll_accuracy = "Polling Average Accuracy",
             market_accuracy = "Market Price Accuracy")

# Percent error from prediction
final_results %>% 
  mutate(market_error = abs(market_close - vote_percent),
         poll_error = abs(poll_estimate - vote_percent)) %>%
  filter(!is.na(market_error) | !is.na(poll_error)) %>% 
  summarize(average_market_error = round(mean(market_error) * 100,2),
            average_poll_error = round(mean(poll_error)*100,2)) %>% 
  gt() %>% 
  tab_header(title = "Average Percent Error of Polls and Prediction Market",
             subtitle = "For Predicting Vote Percent") %>% 
  cols_label(average_market_error = "Market Average Error",
             average_poll_error = "Poll Average Error")


# Logistic model for predicting winner

logistic_mod <- logistic_reg() %>%
    set_engine("glm") %>%
    set_mode("classification")

winner_predictions <- NULL

for (val in 1:100) {
  
  vote_split <- initial_split(final_results)
  vote_train <- training(vote_split)
  vote_test <- testing(vote_split)
  
  winner_predictions <- logistic_mod %>%
    fit(factor(winner) ~ market_close, data = vote_train) %>%
    predict(new_data = vote_test) %>%
    bind_cols(vote_test) %>%
    mutate(model_predicted = .pred_class) %>%
    mutate(model_correct = ifelse(model_predicted == winner, 1, 0)) %>%
    summarize(model_accuracy = sum(model_correct) / n()) %>%
    rbind(winner_predictions)
  
}

winner_predictions %>% 
  summarize(average_accuracy = paste(round(mean(model_accuracy) * 100, 2), "%", sep = ""),
            std_error = round(std.error(model_accuracy) * 100, 2)) %>% 
  gt() %>% 
  tab_header(title = "Average Accuracy of Model Predictions",
             subtitle = "For 1000 Simulations with Resampling of Training and Test Group") %>% 
  cols_label(average_accuracy = "Average Accuracy",
             std_error = "Standard Error")

# Linear model for predicting vote percent

linear_mod <- linear_reg() %>%
  set_engine("lm") %>% 
  set_mode("regression")

linear_mod %>%
  fit(vote_percent ~ poll_estimate * poly(market_close, 3, raw=TRUE), data = vote_train) %>%
  predict(new_data = vote_test) %>%
  bind_cols(vote_test) %>%
  mutate(model_predicted = .pred) %>%
  mutate(model_error = abs(model_predicted - vote_percent)) %>%
  filter(!is.na(model_error)) %>%
  summarize(average_model_error = round(mean(model_error) * 100,2)) %>%
  rbind(vote_predictions_one)
  

```